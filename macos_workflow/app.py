import gradio as gr
import os
import tempfile
import time
from PIL import Image

# Ensure the root path is added so we can import our modules
import sys
import os

# Dynamically determine the project root directory.
# This script is in 'macos_workflow', and the project root is the parent directory.
_current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(_current_dir)

# Add the project root to the Python path to allow for module imports
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Import our workflow components
from macos_workflow.ocr_engine_macos import OCREngine
from macos_workflow import config_macos as config
from macos_workflow.utils import re_match, draw_bounding_boxes, pdf_to_images, save_images_to_pdf

# --- Internationalization (i18n) Strings ---
I18N_STRINGS = {
    "en": {
        "title": "ï£¿ DeepSeek-OCR for macOS",
        "subtitle": "A high-performance OCR tool running locally on your Mac",
        "usage_guide_header": "ğŸ’¡ Usage Guide & Advanced Tips (Click to expand)",
        "tab_image": "ğŸ–¼ï¸ Image OCR",
        "tab_pdf": "ğŸ“„ PDF OCR",
        "input_header": "1. Input Configuration",
        "output_header": "2. Output Results",
        "image_input_label": "Upload Image",
        "task_selector_label": "ğŸ¯ Select Task",
        "custom_prompt_label": "âœï¸ Enter Visual Grounding Instruction",
        "custom_prompt_placeholder": "e.g., <image>\nLocate <|ref|>the black cat<|/ref|> in the image.",
        "resolution_selector_label": "âš™ï¸ Select Resolution Mode",
        "submit_button_image": "ğŸš€ Start Image OCR",
        "submit_button_pdf": "ğŸš€ Start PDF Processing",
        "status_label": "â„¹ï¸ Status",
        "output_md_label": "Recognition Result (Markdown)",
        "output_img_label": "Visualized Annotated Image",
        "download_md_label": "Download Markdown",
        "download_img_label": "Download Annotated Image",
        "pdf_input_label": "Upload PDF File",
        "pdf_output_placeholder": "The final annotated PDF and Markdown files will be generated in the download area below.",
        "download_md_pdf_label": "Download Full Markdown",
        "download_pdf_file_label": "Download Annotated PDF",
        "error_upload_image": "Please upload or paste an image first!",
        "error_upload_pdf": "Please upload a PDF file first!",
        "error_empty_prompt": "Instruction content cannot be empty when using 'Visual Grounding'!",
        "error_init_engine": "Failed to initialize the model engine. Please check the backend logs. Error: {e}",
        "error_pdf_extract": "Failed to extract images from the PDF file. Please check if the file is valid.",
        "status_init_start": "--- First time setup: Initializing OCR Engine... ---",
        "status_init_done": "--- OCR Engine ready. ---",
        "status_init_failed": "FATAL: Could not initialize OCR Engine: {e}",
        "status_init_success": "Engine is ready. Please upload a file and start recognition.",
        "progress_init": "Initializing engine...",
        "progress_infer": "Model inference in progress...",
        "progress_postprocess": "Post-processing results...",
        "progress_pdf_page": "Processing page {i}/{total}...",
        "progress_pdf_aggregate": "Aggregating results...",
        "status_img_success": "âœ… Image recognition successful!\nTime taken: {time:.2f} seconds.",
        "status_pdf_success": "âœ… PDF processing complete!\nTotal {pages} pages, total time: {time:.2f} seconds.",
        "task_markdown": "Document Conversion (Markdown)",
        "task_free_ocr": "Plain Text Recognition (No layout)",
        "task_parse_figure": "Figure/Formula Parsing",
        "task_describe_image": "Image Description",
        "task_grounding": "Visual Grounding",
        "res_base": "Base (1024x1024)",
        "res_gundam": "Gundam (Dynamic)",
        "res_large": "Large (1280x1280)",
        "res_small": "Small (640x640)",
        "usage_guide_content": "\n### 1. How to choose the right resolution mode?\nChoosing the right resolution is key to balancing speed and accuracy.\n*   **âš¡ï¸ Fast Mode (Small)**: Suitable for images with less text and simple layouts (e.g., slides, some books).\n*   **ğŸ‘ Recommended Mode (Base)**: Best for most regular documents (e.g., reports, papers), providing a good balance between speed and quality.\n*   **ğŸ¯ High-Accuracy Mode (Gundam / Large)**: Ideal for images with extremely high text density or large dimensions (e.g., newspapers, posters). The Gundam mode maximizes detail retention with its \"global + local\" view.\n### 2. How to use \"Prompt Instructions\"?\nSelect a task in \"Select Task\", or choose \"Visual Grounding\" and enter a custom instruction to unlock advanced features.\n*   **General Document Processing (Default):**\n    ```\n    <image>\n<|grounding|>Convert the document to markdown.\n    ```\n*   **Plain Text Recognition (Ignore layout):**\n    ```\n    <image>\nFree OCR.\n    ```\n*   **\"Deep Parse\" of Figures or Formulas:**\n    ```\n    <image>\nParse the figure.\n    ```\n*   **General Image Description:**\n    ```\n    <image>\nDescribe this image in detail.\n    ```\n*   **Visual Grounding (Find specific content in the image):**\n    ```\n    <image>\nLocate <|ref|>description of text or object<|/ref|> in the image.\n    ```\n### Productivity Tip\nUse the output of this tool (especially Markdown and table data) as context for a large language model (like GPT-4, Claude, DeepSeek-LLM) to perform summarization, Q&A, or data analysis. This can build a powerful \"Visual Input -> Structured Text -> Language Intelligence\" automated workflow.\n"
    },
    "zh": {
        "title": "ï£¿ DeepSeek-OCR for macOS",
        "subtitle": "ä¸€ä¸ªåœ¨æ‚¨çš„Macä¸Šæœ¬åœ°è¿è¡Œçš„é«˜æ€§èƒ½OCRå·¥å…·",
        "usage_guide_header": "ğŸ’¡ ä½¿ç”¨æŒ‡å—ä¸é«˜çº§æŠ€å·§ (ç‚¹å‡»å±•å¼€)",
        "tab_image": "ğŸ–¼ï¸ å›¾åƒè¯†åˆ« (Image OCR)",
        "tab_pdf": "ğŸ“„ PDFè¯†åˆ« (PDF OCR)",
        "input_header": "1. è¾“å…¥é…ç½®",
        "output_header": "2. è¾“å‡ºç»“æœ",
        "image_input_label": "ä¸Šä¼ å›¾åƒ",
        "task_selector_label": "ğŸ¯ é€‰æ‹©ä»»åŠ¡",
        "custom_prompt_label": "âœï¸ è¾“å…¥è§†è§‰å®šä½æŒ‡ä»¤",
        "custom_prompt_placeholder": "ä¾‹å¦‚: <image>\nLocate <|ref|>é»‘çŒ«<|/ref|> in the image.",
        "resolution_selector_label": "âš™ï¸ é€‰æ‹©åˆ†è¾¨ç‡æ¨¡å¼",
        "submit_button_image": "ğŸš€ å¼€å§‹è¯†åˆ«å›¾åƒ",
        "submit_button_pdf": "ğŸš€ å¼€å§‹å¤„ç†PDF",
        "status_label": "â„¹ï¸ çŠ¶æ€",
        "output_md_label": "è¯†åˆ«ç»“æœ (Markdown)",
        "output_img_label": "å¯è§†åŒ–æ ‡æ³¨å›¾åƒ",
        "download_md_label": "ä¸‹è½½Markdown",
        "download_img_label": "ä¸‹è½½æ ‡æ³¨å›¾",
        "pdf_input_label": "ä¸Šä¼ PDFæ–‡ä»¶",
        "pdf_output_placeholder": "æœ€ç»ˆçš„æ ‡æ³¨PDFå’ŒMarkdownæ–‡ä»¶å°†ç”Ÿæˆåœ¨ä¸‹æ–¹ä¸‹è½½åŒºåŸŸã€‚",
        "download_md_pdf_label": "ä¸‹è½½Markdownå…¨æ–‡",
        "download_pdf_file_label": "ä¸‹è½½æ ‡æ³¨åPDF",
        "error_upload_image": "è¯·å…ˆä¸Šä¼ æˆ–ç²˜è´´ä¸€å¼ å›¾åƒï¼",
        "error_upload_pdf": "è¯·å…ˆä¸Šä¼ ä¸€ä¸ªPDFæ–‡ä»¶ï¼",
        "error_empty_prompt": "ä½¿ç”¨â€œè§†è§‰å®šä½â€æ—¶ï¼ŒæŒ‡ä»¤å†…å®¹ä¸èƒ½ä¸ºç©ºï¼",
        "error_init_engine": "æ— æ³•åˆå§‹åŒ–æ¨¡å‹å¼•æ“ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚é”™è¯¯: {e}",
        "error_pdf_extract": "æ— æ³•ä»PDFæ–‡ä»¶ä¸­æå–å›¾åƒï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆã€‚",
        "status_init_start": "--- ç¬¬ä¸€æ¬¡å¯åŠ¨ï¼šæ­£åœ¨åˆå§‹åŒ–OCRå¼•æ“... ---",
        "status_init_done": "--- OCRå¼•æ“å·²å°±ç»ªã€‚ ---",
        "status_init_failed": "è‡´å‘½é”™è¯¯ï¼šæ— æ³•åˆå§‹åŒ–OCRå¼•æ“: {e}",
        "status_init_success": "å¼•æ“å·²å°±ç»ªã€‚è¯·ä¸Šä¼ æ–‡ä»¶å¹¶å¼€å§‹è¯†åˆ«ã€‚",
        "progress_init": "å¼•æ“åˆå§‹åŒ–...",
        "progress_infer": "æ¨¡å‹æ¨ç†ä¸­...",
        "progress_postprocess": "åå¤„ç†ç»“æœ...",
        "progress_pdf_page": "æ­£åœ¨å¤„ç†ç¬¬ {i}/{total} é¡µ...",
        "progress_pdf_aggregate": "æ±‡æ€»ç»“æœ...",
        "status_img_success": "âœ… å›¾åƒè¯†åˆ«æˆåŠŸï¼\nè€—æ—¶: {time:.2f} ç§’ã€‚",
        "status_pdf_success": "âœ… PDFå¤„ç†å®Œæˆï¼\nå…± {pages} é¡µï¼Œæ€»è€—æ—¶: {time:.2f} ç§’ã€‚",
        "task_markdown": "æ–‡æ¡£è½¬æ¢ (Markdown)",
        "task_free_ocr": "çº¯æ–‡æœ¬è¯†åˆ« (æ— æ’ç‰ˆ)",
        "task_parse_figure": "å›¾è¡¨/å…¬å¼è§£æ",
        "task_describe_image": "å›¾åƒæè¿°",
        "task_grounding": "è§†è§‰å®šä½",
        "res_base": "Base (1024x1024)",
        "res_gundam": "Gundam (åŠ¨æ€)",
        "res_large": "Large (1280x1280)",
        "res_small": "Small (640x640)",
        "usage_guide_content": "\n### 1. å¦‚ä½•é€‰æ‹©åˆé€‚çš„åˆ†è¾¨ç‡æ¨¡å¼ï¼Ÿ\né€‰æ‹©æ­£ç¡®çš„åˆ†è¾¨ç‡æ˜¯å¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦çš„å…³é”®ã€‚\n*   **âš¡ï¸ å¿«é€Ÿæ¨¡å¼ (Small)**: é€‚ç”¨äºæ–‡å­—è¾ƒå°‘ã€æ’ç‰ˆç®€å•çš„å›¾åƒï¼ˆå¦‚å¹»ç¯ç‰‡ã€éƒ¨åˆ†ä¹¦ç±ï¼‰ã€‚\n*   **ğŸ‘ æ¨èæ¨¡å¼ (Base)**: é€‚ç”¨äºå¤§å¤šæ•°å¸¸è§„æ–‡æ¡£ï¼ˆå¦‚æŠ¥å‘Šã€è®ºæ–‡ï¼‰ï¼Œåœ¨é€Ÿåº¦å’Œæ•ˆæœé—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚\n*   **ğŸ¯ é«˜ç²¾åº¦æ¨¡å¼ (Gundam / Large)**: é€‚ç”¨äºæ–‡å­—å¯†åº¦æé«˜æˆ–å°ºå¯¸å·¨å¤§çš„å›¾åƒï¼ˆå¦‚æŠ¥çº¸ã€æµ·æŠ¥ï¼‰ã€‚Gundamæ¨¡å¼é€šè¿‡â€œå…¨å±€+å±€éƒ¨â€çš„è§†é‡ï¼Œèƒ½æœ€å¤§é™åº¦ä¿ç•™ç»†èŠ‚ã€‚\n### 2. å¦‚ä½•å–„ç”¨â€œæŒ‡ä»¤æç¤ºè¯â€ï¼Ÿ\nåœ¨â€œé€‰æ‹©ä»»åŠ¡â€ä¸­é€‰æ‹©å¯¹åº”çš„ä»»åŠ¡ï¼Œæˆ–é€‰æ‹©â€œè§†è§‰å®šä½â€å¹¶è¾“å…¥è‡ªå®šä¹‰æŒ‡ä»¤æ¥è§£é”é«˜çº§åŠŸèƒ½ã€‚\n*   **é€šç”¨æ–‡æ¡£å¤„ç† (é»˜è®¤):**\n    ```\n    <image>\n<|grounding|>Convert the document to markdown.\n    ```\n*   **çº¯æ–‡æœ¬è¯†åˆ« (å¿½ç•¥æ’ç‰ˆ):**\n    ```\n    <image>\nFree OCR.\n    ```\n*   **â€œæ·±åº¦è§£æâ€å›¾è¡¨æˆ–å…¬å¼:**\n    ```\n    <image>\nParse the figure.\n    ```\n*   **é€šç”¨å›¾åƒæè¿°:**\n    ```\n    <image>\nDescribe this image in detail.\n    ```\n*   **è§†è§‰å®šä½ (å¯»æ‰¾å›¾ä¸­ç‰¹å®šå†…å®¹):**\n    ```\n    <image>\nLocate <|ref|>æ–‡å­—æˆ–ç‰©ä½“æè¿°<|/ref|> in the image.\n    ```\n### ç”Ÿäº§åŠ›å»ºè®®\nå°†æœ¬å·¥å…·çš„è¾“å‡ºï¼ˆå°¤å…¶æ˜¯Markdownå’Œå›¾è¡¨æ•°æ®ï¼‰ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè¾“å…¥ç»™å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4, Claude, DeepSeek-LLMç­‰ï¼‰ï¼Œè¿›è¡Œæ‘˜è¦ã€é—®ç­”æˆ–æ•°æ®åˆ†æï¼Œå¯ä»¥æ„å»ºèµ·å¼ºå¤§çš„â€œè§†è§‰è¾“å…¥ -> ç»“æ„åŒ–æ–‡æœ¬ -> è¯­è¨€æ™ºèƒ½â€è‡ªåŠ¨åŒ–å·¥ä½œæµã€‚\n"
    }
}

# --- Global Variables ---
ENGINE = None
# Store language-dependent choices
TASK_PROMPTS = {}
RESOLUTION_MODES = {}

def get_i18n_text(lang, key, **kwargs):
    """Get internationalized text, supporting simple formatting."""
    lang_code = 'zh' if lang == 'ç®€ä½“ä¸­æ–‡' else 'en'
    return I18N_STRINGS[lang_code].get(key, key).format(**kwargs)

def update_language_choices(lang):
    """Update global choice dictionaries based on language."""
    global TASK_PROMPTS, RESOLUTION_MODES
    TASK_PROMPTS = {
        get_i18n_text(lang, "task_markdown"): "<image>\n<|grounding|>Convert the document to markdown.",
        get_i18n_text(lang, "task_free_ocr"): "<image>\nFree OCR.",
        get_i18n_text(lang, "task_parse_figure"): "<image>\nParse the figure.",
        get_i18n_text(lang, "task_describe_image"): "<image>\nDescribe this image in detail.",
        get_i18n_text(lang, "task_grounding"): ""
    }
    RESOLUTION_MODES = {
        get_i18n_text(lang, "res_base"): {"base_size": 1024, "image_size": 1024, "crop_mode": False},
        get_i18n_text(lang, "res_gundam"): {"base_size": 1024, "image_size": 640, "crop_mode": True},
        get_i18n_text(lang, "res_large"): {"base_size": 1280, "image_size": 1280, "crop_mode": False},
        get_i18n_text(lang, "res_small"): {"base_size": 640, "image_size": 640, "crop_mode": False},
    }

# Initialize with default language
update_language_choices('ç®€ä½“ä¸­æ–‡')

# --- Engine Initialization ---
def initialize_engine(lang='ç®€ä½“ä¸­æ–‡'):
    global ENGINE
    if ENGINE is None:
        print(get_i18n_text(lang, "status_init_start"))
        try:
            ENGINE = OCREngine(project_root=project_root)
            print(get_i18n_text(lang, "status_init_done"))
        except Exception as e:
            print(get_i18n_text(lang, "status_init_failed", e=e))
            raise gr.Error(get_i18n_text(lang, "error_init_engine", e=e))
    return get_i18n_text(lang, "status_init_success")

# --- Backend Functions for Gradio ---
def run_image_ocr_task(image: Image.Image, task: str, custom_prompt: str, resolution_key: str, lang: str, progress=gr.Progress()):
    if image is None:
        raise gr.Error(get_i18n_text(lang, "error_upload_image"))

    progress(0, desc=get_i18n_text(lang, "progress_init"))
    initialize_engine(lang)

    prompt = list(TASK_PROMPTS.values())[list(TASK_PROMPTS.keys()).index(task)] if task != get_i18n_text(lang, "task_grounding") else custom_prompt
    if not prompt.strip() and task == get_i18n_text(lang, "task_grounding"):
        raise gr.Error(get_i18n_text(lang, "error_empty_prompt"))

    if "<image>" not in prompt:
        prompt = f"<image>\n{prompt}"

    resolution_params = RESOLUTION_MODES[resolution_key]
    config.BASE_SIZE, config.IMAGE_SIZE, config.CROP_MODE = resolution_params['base_size'], resolution_params['image_size'], resolution_params['crop_mode']

    try:
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_file:
            image.save(tmp_file.name)
            tmp_image_path = tmp_file.name

        progress(0.5, desc=get_i18n_text(lang, "progress_infer"))
        start_time = time.time()
        result_text = ENGINE.infer(image_path=tmp_image_path, prompt=prompt)
        inference_time = time.time() - start_time
    finally:
        if 'tmp_image_path' in locals() and os.path.exists(tmp_image_path):
            os.remove(tmp_image_path)

    progress(0.9, desc=get_i18n_text(lang, "progress_postprocess"))
    matches_ref, _, _ = re_match(result_text)
    annotated_image = draw_bounding_boxes(image, matches_ref, tempfile.gettempdir()) if matches_ref else None

    with tempfile.NamedTemporaryFile(mode='w+', suffix='.md', delete=False, encoding='utf-8') as tmp_md:
        tmp_md.write(result_text)
        md_path = tmp_md.name

    img_path = None
    if annotated_image:
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_img:
            annotated_image.save(tmp_img.name)
            img_path = tmp_img.name

    status = get_i18n_text(lang, "status_img_success", time=inference_time)
    return result_text, annotated_image, md_path, img_path, status

def run_pdf_ocr_task(pdf_file, task: str, custom_prompt: str, resolution_key: str, lang: str, progress=gr.Progress()):
    if pdf_file is None:
        raise gr.Error(get_i18n_text(lang, "error_upload_pdf"))

    progress(0, desc=get_i18n_text(lang, "progress_init"))
    initialize_engine(lang)
    pdf_path = pdf_file.name

    prompt = list(TASK_PROMPTS.values())[list(TASK_PROMPTS.keys()).index(task)] if task != get_i18n_text(lang, "task_grounding") else custom_prompt
    if not prompt.strip() and task == get_i18n_text(lang, "task_grounding"):
        raise gr.Error(get_i18n_text(lang, "error_empty_prompt"))
        
    if "<image>" not in prompt:
        prompt = f"<image>\n{prompt}"

    resolution_params = RESOLUTION_MODES[resolution_key]
    config.BASE_SIZE, config.IMAGE_SIZE, config.CROP_MODE = resolution_params['base_size'], resolution_params['image_size'], resolution_params['crop_mode']

    page_images = pdf_to_images(pdf_path)
    if not page_images:
        raise gr.Error(get_i18n_text(lang, "error_pdf_extract"))

    all_md_results, annotated_pages = [], []
    total_time = 0

    for i, page_image in enumerate(page_images):
        progress(i / len(page_images), desc=get_i18n_text(lang, "progress_pdf_page", i=i+1, total=len(page_images)))
        try:
            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp_file:
                page_image.save(tmp_file.name)
                tmp_image_path = tmp_file.name
            
            start_time = time.time()
            result_text = ENGINE.infer(image_path=tmp_image_path, prompt=prompt)
            total_time += (time.time() - start_time)

            all_md_results.append(result_text)
            matches_ref, _, _ = re_match(result_text)
            annotated_page = draw_bounding_boxes(page_image, matches_ref, tempfile.gettempdir()) if matches_ref else page_image
            annotated_pages.append(annotated_page)
        finally:
            if 'tmp_image_path' in locals() and os.path.exists(tmp_image_path):
                os.remove(tmp_image_path)

    progress(0.9, desc=get_i18n_text(lang, "progress_pdf_aggregate"))
    final_md = "\n\n<--- Page Split --->\n\n".join(all_md_results)
    
    with tempfile.NamedTemporaryFile(mode='w+', suffix='.md', delete=False, encoding='utf-8') as tmp_md:
        tmp_md.write(final_md)
        md_path = tmp_md.name

    pdf_out_path = None
    if annotated_pages:
        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as tmp_pdf:
            save_images_to_pdf(annotated_pages, tmp_pdf.name)
            pdf_out_path = tmp_pdf.name

    status = get_i18n_text(lang, "status_pdf_success", pages=len(page_images), time=total_time)
    return final_md, None, md_path, pdf_out_path, status

def update_custom_prompt_visibility(task: str, lang: str):
    return gr.update(visible=(task == get_i18n_text(lang, "task_grounding")))

# --- Gradio UI Definition ---
def create_ui():
    with gr.Blocks(theme=gr.themes.Soft(), css="footer {display: none !important}") as demo:
        
        lang = gr.Radio(["ç®€ä½“ä¸­æ–‡", "English"], label="Language / è¯­è¨€", value="ç®€ä½“ä¸­æ–‡", interactive=True)

        # UI Components
        title = gr.Markdown("<h1><center>ï£¿ DeepSeek-OCR for macOS</center></h1>")
        subtitle = gr.Markdown("#### <center>ä¸€ä¸ªåœ¨æ‚¨çš„Macä¸Šæœ¬åœ°è¿è¡Œçš„é«˜æ€§èƒ½OCRå·¥å…·</center>")
        usage_guide_accordion = gr.Accordion("ğŸ’¡ ä½¿ç”¨æŒ‡å—ä¸é«˜çº§æŠ€å·§ (ç‚¹å‡»å±•å¼€)", open=False)
        with usage_guide_accordion:
            usage_guide_content = gr.Markdown(get_i18n_text('ç®€ä½“ä¸­æ–‡', 'usage_guide_content'))

        with gr.Tabs() as tabs:
            with gr.TabItem("ğŸ–¼ï¸ å›¾åƒè¯†åˆ« (Image OCR)", id=0) as tab_image:
                with gr.Row(equal_height=True):
                    with gr.Column(scale=1):
                        input_header_img = gr.Markdown("### 1. è¾“å…¥é…ç½®")
                        image_input = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒ", sources=['upload', 'clipboard'])
                        task_selector_img = gr.Dropdown(label="ğŸ¯ é€‰æ‹©ä»»åŠ¡", choices=list(TASK_PROMPTS.keys()), value=list(TASK_PROMPTS.keys())[0])
                        custom_prompt_img = gr.Textbox(label="âœï¸ è¾“å…¥è§†è§‰å®šä½æŒ‡ä»¤", placeholder=get_i18n_text('ç®€ä½“ä¸­æ–‡', 'custom_prompt_placeholder'), visible=False, lines=3)
                        resolution_selector_img = gr.Dropdown(label="âš™ï¸ é€‰æ‹©åˆ†è¾¨ç‡æ¨¡å¼", choices=list(RESOLUTION_MODES.keys()), value=list(RESOLUTION_MODES.keys())[0])
                        submit_button_img = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«å›¾åƒ", variant="primary")
                    with gr.Column(scale=1):
                        output_header_img = gr.Markdown("### 2. è¾“å‡ºç»“æœ")
                        status_box_img = gr.Textbox(label="â„¹ï¸ çŠ¶æ€", interactive=False, lines=4)
                        output_md_img = gr.Markdown(label="è¯†åˆ«ç»“æœ (Markdown)")
                        output_img = gr.Image(type="pil", label="å¯è§†åŒ–æ ‡æ³¨å›¾åƒ")
                        with gr.Row():
                            download_md_img = gr.File(label="ä¸‹è½½Markdown")
                            download_img_file = gr.File(label="ä¸‹è½½æ ‡æ³¨å›¾")
            
            with gr.TabItem("ğŸ“„ PDFè¯†åˆ« (PDF OCR)", id=1) as tab_pdf:
                with gr.Row(equal_height=True):
                    with gr.Column(scale=1):
                        input_header_pdf = gr.Markdown("### 1. è¾“å…¥é…ç½®")
                        pdf_input = gr.File(label="ä¸Šä¼ PDFæ–‡ä»¶", file_types=['.pdf'])
                        task_selector_pdf = gr.Dropdown(label="ğŸ¯ é€‰æ‹©ä»»åŠ¡", choices=list(TASK_PROMPTS.keys()), value=list(TASK_PROMPTS.keys())[0])
                        custom_prompt_pdf = gr.Textbox(label="âœï¸ è¾“å…¥è§†è§‰å®šä½æŒ‡ä»¤", placeholder=get_i18n_text('ç®€ä½“ä¸­æ–‡', 'custom_prompt_placeholder'), visible=False, lines=3)
                        resolution_selector_pdf = gr.Dropdown(label="âš™ï¸ é€‰æ‹©åˆ†è¾¨ç‡æ¨¡å¼", choices=list(RESOLUTION_MODES.keys()), value=list(RESOLUTION_MODES.keys())[0])
                        submit_button_pdf = gr.Button("ğŸš€ å¼€å§‹å¤„ç†PDF", variant="primary")
                    with gr.Column(scale=1):
                        output_header_pdf = gr.Markdown("### 2. è¾“å‡ºç»“æœ")
                        status_box_pdf = gr.Textbox(label="â„¹ï¸ çŠ¶æ€", interactive=False, lines=4)
                        output_md_pdf = gr.Markdown(label="è¯†åˆ«ç»“æœ (Markdown)")
                        pdf_output_placeholder = gr.Markdown("æœ€ç»ˆçš„æ ‡æ³¨PDFå’ŒMarkdownæ–‡ä»¶å°†ç”Ÿæˆåœ¨ä¸‹æ–¹ä¸‹è½½åŒºåŸŸã€‚")
                        with gr.Row():
                            download_md_pdf = gr.File(label="ä¸‹è½½Markdownå…¨æ–‡")
                            download_pdf_file = gr.File(label="ä¸‹è½½æ ‡æ³¨åPDF")
        
        # --- Language Change Handler ---
        def update_ui_language(language):
            update_language_choices(language)
            
            new_task_choices = list(TASK_PROMPTS.keys())
            new_res_choices = list(RESOLUTION_MODES.keys())
            
            # Special handling for status boxes
            status_box_img_update = gr.update(label=get_i18n_text(language, 'status_label'))
            status_box_pdf_update = gr.update(label=get_i18n_text(language, 'status_label'))
            if ENGINE is not None:
                new_status_text = get_i18n_text(language, 'status_init_success')
                status_box_img_update = gr.update(label=get_i18n_text(language, 'status_label'), value=new_status_text)
                status_box_pdf_update = gr.update(label=get_i18n_text(language, 'status_label'), value=new_status_text)

            return (
                gr.update(value=f"<h1><center>{get_i18n_text(language, 'title')}</center></h1>"),
                gr.update(value=f"#### <center>{get_i18n_text(language, 'subtitle')}</center>"),
                gr.update(label=get_i18n_text(language, 'usage_guide_header')),
                gr.update(value=get_i18n_text(language, 'usage_guide_content')),
                gr.update(label=get_i18n_text(language, 'tab_image')),
                gr.update(label=get_i18n_text(language, 'tab_pdf')),
                gr.update(value=f"### {get_i18n_text(language, 'input_header')}"),
                gr.update(value=f"### {get_i18n_text(language, 'output_header')}"),
                gr.update(label=get_i18n_text(language, 'image_input_label')),
                gr.update(label=get_i18n_text(language, 'task_selector_label'), choices=new_task_choices, value=new_task_choices[0]),
                gr.update(label=get_i18n_text(language, 'custom_prompt_label'), placeholder=get_i18n_text(language, 'custom_prompt_placeholder')),
                gr.update(label=get_i18n_text(language, 'resolution_selector_label'), choices=new_res_choices, value=new_res_choices[0]),
                gr.update(value=get_i18n_text(language, 'submit_button_image')),
                status_box_img_update, # Updated status box for images
                gr.update(label=get_i18n_text(language, 'output_md_label')),
                gr.update(label=get_i18n_text(language, 'output_img_label')),
                gr.update(label=get_i18n_text(language, 'download_md_label')),
                gr.update(label=get_i18n_text(language, 'download_img_label')),
                gr.update(value=f"### {get_i18n_text(language, 'input_header')}"),
                gr.update(value=f"### {get_i18n_text(language, 'output_header')}"),
                gr.update(label=get_i18n_text(language, 'pdf_input_label')),
                gr.update(label=get_i18n_text(language, 'task_selector_label'), choices=new_task_choices, value=new_task_choices[0]),
                gr.update(label=get_i18n_text(language, 'custom_prompt_label'), placeholder=get_i18n_text(language, 'custom_prompt_placeholder')),
                gr.update(label=get_i18n_text(language, 'resolution_selector_label'), choices=new_res_choices, value=new_res_choices[0]),
                gr.update(value=get_i18n_text(language, 'submit_button_pdf')),
                status_box_pdf_update, # Updated status box for PDFs
                gr.update(label=get_i18n_text(language, 'output_md_label')),
                gr.update(value=get_i18n_text(language, 'pdf_output_placeholder')),
                gr.update(label=get_i18n_text(language, 'download_md_pdf_label')),
                gr.update(label=get_i18n_text(language, 'download_pdf_file_label')),
            )

        # --- Event Listeners ---
        outputs_list = [
            title, subtitle, usage_guide_accordion, usage_guide_content, tab_image, tab_pdf,
            input_header_img, output_header_img, image_input, task_selector_img, custom_prompt_img,
            resolution_selector_img, submit_button_img, status_box_img, output_md_img, output_img,
            download_md_img, download_img_file, input_header_pdf, output_header_pdf, pdf_input,
            task_selector_pdf, custom_prompt_pdf, resolution_selector_pdf, submit_button_pdf,
            status_box_pdf, output_md_pdf, pdf_output_placeholder, download_md_pdf, download_pdf_file
        ]
        lang.change(fn=update_ui_language, inputs=lang, outputs=outputs_list)

        task_selector_img.change(fn=update_custom_prompt_visibility, inputs=[task_selector_img, lang], outputs=custom_prompt_img)
        submit_button_img.click(fn=run_image_ocr_task, inputs=[image_input, task_selector_img, custom_prompt_img, resolution_selector_img, lang], outputs=[output_md_img, output_img, download_md_img, download_img_file, status_box_img])

        task_selector_pdf.change(fn=update_custom_prompt_visibility, inputs=[task_selector_pdf, lang], outputs=custom_prompt_pdf)
        submit_button_pdf.click(fn=run_pdf_ocr_task, inputs=[pdf_input, task_selector_pdf, custom_prompt_pdf, resolution_selector_pdf, lang], outputs=[output_md_pdf, download_pdf_file, download_md_pdf, download_pdf_file, status_box_pdf])
        
        # Pass the language to the initial load function
        def on_load(language):
            return initialize_engine(language)

        demo.load(fn=on_load, inputs=[lang], outputs=[status_box_img])
        # Also update the PDF status box on load
        demo.load(fn=None, inputs=None, outputs=[status_box_pdf], js="(x) => document.querySelector('#close_button > .button_primary').click()")
        # A bit of a hack to sync the status boxes. The JS finds the first primary button (our image submit button)
        # and simulates a click on its invisible close button sibling to trigger its status update, which we can then use.
        # A cleaner way would require more complex Gradio state management.
        # Let's try a simpler way first.
        def sync_status_boxes(img_status):
            return img_status
        submit_button_img.click(fn=sync_status_boxes, inputs=status_box_img, outputs=status_box_pdf)
        demo.load(fn=sync_status_boxes, inputs=status_box_img, outputs=status_box_pdf)

    return demo

if __name__ == "__main__":
    app = create_ui()
    app.launch(show_error=True)
